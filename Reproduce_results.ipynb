{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ImageNet16-120' # choose between 'ImageNet16-120', 'cifar10' and 'cifar100'\n",
    "data_loc = '../datasets/ImageNet16' # choose ImageNet16 for ImageNet16-120 and cifar for cifar10 and cifar100\n",
    "api_loc = '../datasets/NAS-Bench-201-v1_1-096897.pth'\n",
    "n_runs = 500\n",
    "n_init = 100\n",
    "n_samples = 1000\n",
    "batch_size = 256\n",
    "trainval = False # set to True to get access to the validation error for cifar10\n",
    "GPU = '0' # choose the GPU to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from statistics import mean\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "seed = 1\n",
    "\n",
    "save_loc = 'results'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import get_cell_based_tiny_net\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Setting the seed\n",
    "def prepare_seed(rand_seed):\n",
    "    torch.manual_seed(rand_seed)\n",
    "    torch.cuda.manual_seed(rand_seed)\n",
    "    torch.cuda.manual_seed_all(rand_seed)\n",
    "\n",
    "# Colormap for plots\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap  \n",
    "\n",
    "def plot_test(scores, accs, nparams):\n",
    "    cmap = plt.get_cmap('inferno_r')\n",
    "    new_cmap = truncate_colormap(cmap, 0.12, 0.63)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.box(on=None)\n",
    "    plt.grid(color='#dbdbd9', linewidth=0.5)\n",
    "    plt.xlabel('Trained accuracy', fontsize = 12)\n",
    "    plt.ylabel('$\\sigma_{R}$', fontsize = 12)\n",
    "    plt.scatter(np.array(accs),\n",
    "                np.array(scores), \n",
    "                s=20,\n",
    "                c=np.log10(np.array(nparams)),\n",
    "                cmap=new_cmap,\n",
    "                vmin=np.log10(np.min(nparams)),\n",
    "                vmax=np.log10(np.max(nparams))\n",
    "                )\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def initialize_resnet(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        #changed here\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import get_datasets\n",
    "from config_utils import load_config\n",
    "from nas_201_api import NASBench201API as API\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "THE_START = time.time()\n",
    "api = API(api_loc, verbose = False)\n",
    "\n",
    "train_data, valid_data, xshape, class_num = get_datasets(dataset, data_loc, cutout=0)\n",
    "if dataset == 'cifar10':\n",
    "    acc_type = 'ori-test'\n",
    "    val_acc_type = 'x-valid'\n",
    "\n",
    "else:\n",
    "    acc_type = 'x-test'\n",
    "    val_acc_type = 'x-valid'\n",
    "\n",
    "if trainval:\n",
    "    cifar_split = load_config('config_utils/cifar-split.txt', None, None)\n",
    "    train_split, valid_split = cifar_split.train, cifar_split.valid\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                               num_workers=0, pin_memory=True, sampler= torch.utils.data.sampler.SubsetRandomSampler(train_split))\n",
    "\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=0, pin_memory=True)\n",
    "\n",
    "times     = []\n",
    "chosen    = []\n",
    "acc       = []\n",
    "val_acc   = []\n",
    "topscores = []\n",
    "\n",
    "dset = dataset if not trainval else 'cifar10-valid'\n",
    "\n",
    "save_dir = './results/{}bs_{}it_{}runs_{}arch/'.format(batch_size, n_init, n_runs, n_samples)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "if trainval:\n",
    "    logs_filename = save_dir + 'logs_' + dataset.upper() +  'val.txt'\n",
    "else:\n",
    "    logs_filename = save_dir + 'logs_' + dataset.upper() +  '.txt'\n",
    "with open(logs_filename, 'w') as logs:\n",
    "    logs.write(\"Starting logging...\\n\")\n",
    "    ind_actual_best_mean = 0\n",
    "    runs = trange(n_runs, desc='acc: ')\n",
    "    for N in runs:\n",
    "        start = time.time()\n",
    "        # Randomly select n_samples architectures\n",
    "        indices = np.random.randint(0,15625,n_samples)\n",
    "        data_iterator = iter(train_loader)\n",
    "        x, target = next(data_iterator)\n",
    "        x, target = x.to(device), target.to(device)\n",
    "        scores = []\n",
    "        acc_run = []\n",
    "        acc_run_cur = []\n",
    "        nparams = []\n",
    "        for arch in indices:\n",
    "            config = api.get_net_config(arch, dataset)\n",
    "            info = api.query_by_index(arch, hp='200')\n",
    "            acc_run.append(info.get_metrics(dset, acc_type)['accuracy'])\n",
    "            network = get_cell_based_tiny_net(config)  # create the network from configuration\n",
    "            # Compute the number of parameters\n",
    "            nparams.append(sum(p.numel() for p in network.parameters()))\n",
    "            network = network.to(device)\n",
    "            untrained_acc = []\n",
    "            # Test the same network with different initializations\n",
    "            for seed in range(n_init):\n",
    "                # Initialise the network with the seed\n",
    "                prepare_seed(seed)\n",
    "                network.apply(initialize_resnet)\n",
    "                # Propagate through the network once\n",
    "                _, y_pred = network(x)\n",
    "                # Get predictions\n",
    "                label_pred = torch.argmax(y_pred, dim=1)\n",
    "                # Compute accuracy\n",
    "                coinc = torch.sum(torch.eq(label_pred, target))\n",
    "                pred_accuracy = coinc.cpu().detach().numpy()/batch_size\n",
    "                untrained_acc.append(pred_accuracy)\n",
    "            # Condition takes care of random informationless networks, that give 0 standard deviation\n",
    "            if np.std(untrained_acc)>0.0:\n",
    "                # Compute the score\n",
    "                scores.append(np.std(untrained_acc)/np.mean(untrained_acc))\n",
    "            else:\n",
    "                # Otherwise set the score to some large value\n",
    "                scores.append(999)\n",
    "            \n",
    "            \n",
    "        acc_run.sort(reverse=True)\n",
    "        best_arch = indices[np.argmin(scores)]\n",
    "        info_best = api.query_by_index(best_arch, hp='200')\n",
    "        ind_actual_best = acc_run.index(info_best.get_metrics(dset, acc_type)['accuracy'])\n",
    "        ind_actual_best_mean += ind_actual_best\n",
    "\n",
    "    #     print(\"Actual ranking: \" + str(ind_actual_best))# + '/' + str(ind_actual_best_median))\n",
    "        topscores.append(scores[np.argmin(scores)])\n",
    "        chosen.append(best_arch)\n",
    "        acc.append(info_best.get_metrics(dset, acc_type)['accuracy'])\n",
    "\n",
    "        if not dataset == 'cifar10' or trainval:\n",
    "            val_acc.append(info_best.get_metrics(dset, val_acc_type)['accuracy'])\n",
    "    #         val_acc_median.append(info_best_median.get_metrics(dset, val_acc_type)['accuracy'])\n",
    "        logs.write(f\"Mean acc: {mean(acc if not trainval else val_acc):.2f}% \")\n",
    "        logs.write(f\"Actual ranking: {ind_actual_best} \\n\")\n",
    "#         print(f\"Actual ranking: {ind_actual_best} \\n\")\n",
    "        times.append(time.time()-start)\n",
    "        runs.set_description(f\"mean acc: {mean(acc if not trainval else val_acc):.2f}%\")\n",
    "    \n",
    "    logs.write(f\"Average chosen architecure's rank: {ind_actual_best_mean/n_runs} \\n\")\n",
    "    logs.write(f\"Final mean test accuracy: {np.mean(acc)} +- {np.std(acc)} \\n\")\n",
    "    logs.write(f\"Median duration: {np.median(times)} \\n\")\n",
    "    if len(val_acc) > 1:\n",
    "        logs.write(f\"Final mean validation accuracy: {np.mean(val_acc)} +- {np.std(val_acc)} \\n\")\n",
    "    \n",
    "\n",
    "state = {'accs': acc,\n",
    "         'val_accs': val_acc,\n",
    "         'chosen': chosen,\n",
    "         'times': times,\n",
    "         'topscores': topscores,\n",
    "         }\n",
    "\n",
    "dset = dataset if not trainval else 'cifar10-valid'\n",
    "fname = f\"{save_loc}/{dset}_{n_runs}_{n_samples}_{seed}.t7\"\n",
    "torch.save(state, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
